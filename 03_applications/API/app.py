"""
üö® Fraud Detection API - Level UP Edition
=========================================

API FastAPI pour la d√©tection de fraude en temps r√©el
avec preprocessing et feature engineering

Fonctionnalit√©s:
- Download automatique du model + preprocessor depuis HuggingFace
- 3 endpoints: /predict, /preprocess, /feat_eng
- Feature engineering complet (distance GPS, features temporelles, √¢ge)
- Documentation interactive sur /docs

Author: Terorra
Date: January 2026
Version: 2.0.0
"""

# =====================================================================
# IMPORTS
# =====================================================================

# FastAPI et types
from fastapi import FastAPI, HTTPException, status
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any

# HuggingFace pour t√©l√©charger les mod√®les
from huggingface_hub import hf_hub_download

# ML et data
import joblib
import pandas as pd
import numpy as np

# Utilitaires
import os
from datetime import datetime
import time

# Notre module de feature engineering
from feature_engineering import (
    engineer_features,
    prepare_for_model,
    get_model_features,
    haversine_distance,
    extract_time_features
)


# =====================================================================
# CONFIGURATION GLOBALE
# =====================================================================

# Repository HuggingFace o√π sont stock√©s les mod√®les
REPO_ID = "Terorra/fd_model_jedha"

# Noms des fichiers sur HuggingFace
MODEL_FILENAME = "fraud_model.pkl"           # Le mod√®le RandomForest
PREPROCESSOR_FILENAME = "preprocessor.pkl"   # Le preprocessor (ColumnTransformer)

# Version du mod√®le (None = latest, ou "v1", "v2", etc.)
MODEL_VERSION = None


# =====================================================================
# VARIABLES GLOBALES (mod√®les charg√©s en m√©moire)
# =====================================================================

# Ces variables seront remplies au d√©marrage de l'API
model = None         # Le mod√®le ML (RandomForestClassifier)
preprocessor = None  # Le preprocessor (StandardScaler + OneHotEncoder)


# =====================================================================
# CR√âATION DE L'APPLICATION FASTAPI
# =====================================================================

app = FastAPI(
    # Titre qui appara√Æt dans la doc
    title="üö® Fraud Detection API - Level UP",
    
    # Description compl√®te (supporte Markdown)
    description="""
    # API de D√©tection de Fraude en Temps R√©el
    
    Cette API utilise le Machine Learning pour d√©tecter les transactions frauduleuses
    sur les cartes de cr√©dit.
    
    ## üöÄ Fonctionnalit√©s
    
    ### Endpoints Principaux
    
    1. **`/predict`** - Pr√©diction compl√®te
       - Prend les donn√©es brutes
       - Applique le feature engineering
       - Applique le preprocessing
       - Retourne la pr√©diction de fraude
    
    2. **`/feat_eng`** - Feature Engineering seulement
       - Calcule la distance GPS client-marchand
       - Extrait les features temporelles (heure, jour, weekend, etc.)
       - Calcule l'√¢ge du porteur
       - Retourne les features transform√©es
    
    3. **`/preprocess`** - Preprocessing seulement
       - Prend les features (d√©j√† engineered)
       - Applique StandardScaler (normalisation)
       - Applique OneHotEncoder (encoding cat√©gories)
       - Retourne les features preprocessed (pr√™tes pour le mod√®le)
    
    ### Endpoints Utilitaires
    
    - **`/health`** - V√©rifier que l'API fonctionne
    - **`/model/info`** - Informations sur le mod√®le ML
    - **`/features`** - Liste des features n√©cessaires
    
    ## üìä Workflow Complet
    
    ```
    Donn√©es Brutes
        ‚Üì
    /feat_eng ‚Üí Feature Engineering
        ‚Üì
    /preprocess ‚Üí Preprocessing (scaling + encoding)
        ‚Üì
    /predict ‚Üí Pr√©diction ML
        ‚Üì
    R√©sultat: Fraude ou Non
    ```
    
    ## üéØ Mod√®le ML
    
    - **Algorithme**: RandomForestClassifier
    - **Recall**: > 90% (optimis√© pour d√©tecter les fraudes)
    - **Features**: 21 features (17 num√©riques + 4 cat√©gorielles)
    - **Preprocessing**: StandardScaler + OneHotEncoder
    - **H√©bergement**: HuggingFace Hub
    
    ## üí° Cas d'Usage
    
    1. **Validation en temps r√©el**: Valider une transaction au moment du paiement
    2. **Analyse batch**: Analyser des milliers de transactions historiques
    3. **Monitoring**: Surveiller les patterns de fraude
    4. **Reporting**: G√©n√©rer des rapports de fraude
    
    ## üîß Feature Engineering
    
    L'API calcule automatiquement:
    - **distance_km**: Distance GPS entre client et marchand (formule Haversine)
    - **hour**: Heure de la transaction (0-23)
    - **is_night, is_morning, is_afternoon, is_evening**: P√©riode de la journ√©e
    - **is_business_hour**: Transaction pendant heures de bureau (8h-17h)
    - **is_weekend**: Transaction le weekend
    - **age**: √Çge du porteur de carte
    - **year, month, day, dayofweek**: Composantes de la date
    
    ## üìö Documentation
    
    - Cette page: Documentation interactive avec exemples
    - Essayez les endpoints directement depuis cette page!
    - Chaque endpoint a des exemples pr√©-remplis
    
    ## üéì Pour Commencer
    
    1. Testez `/health` pour v√©rifier que l'API fonctionne
    2. Regardez `/features` pour voir les features n√©cessaires
    3. Essayez `/feat_eng` avec des donn√©es de test
    4. Utilisez `/predict` pour une pr√©diction compl√®te
    """,
    
    version="2.0.0",
    
    contact={
        "name": "Terorra",
        "email": "your.email@example.com",
    },
    
    license_info={
        "name": "MIT",
    },
    
    # Tags pour organiser les endpoints dans la doc
    openapi_tags=[
        {
            "name": "üéØ Prediction",
            "description": "Endpoints de pr√©diction de fraude"
        },
        {
            "name": "üîß Feature Engineering",
            "description": "Transformation des features"
        },
        {
            "name": "‚öôÔ∏è Preprocessing",
            "description": "Preprocessing des donn√©es"
        },
        {
            "name": "üìä Information",
            "description": "Informations sur l'API et le mod√®le"
        },
    ]
)


# =====================================================================
# SCHEMAS PYDANTIC (D√©finition des types de donn√©es)
# =====================================================================

class TransactionRawInput(BaseModel):
    """
    Donn√©es BRUTES d'une transaction (avant feature engineering)
    
    Ce sont les donn√©es telles qu'elles arrivent de la base de donn√©es
    ou du syst√®me de paiement, SANS transformation.
    """
    # Informations carte
    cc_num: int = Field(
        ...,
        description="Num√©ro de carte de cr√©dit (hash√©)",
        example=374125201044065
    )
    
    # Montant
    amt: float = Field(
        ...,
        description="Montant de la transaction en dollars",
        example=150.75,
        gt=0
    )
    
    # Localisation client
    lat: float = Field(
        ...,
        description="Latitude du client (coordonn√©es GPS)",
        example=40.7128,
        ge=-90,
        le=90
    )
    long: float = Field(
        ...,
        description="Longitude du client (coordonn√©es GPS)",
        example=-74.0060,
        ge=-180,
        le=180
    )
    
    # Ville
    city_pop: int = Field(
        ...,
        description="Population de la ville du client",
        example=8000000,
        gt=0
    )
    zip: int = Field(
        ...,
        description="Code postal",
        example=10001
    )
    
    # Localisation marchand
    merch_lat: float = Field(
        ...,
        description="Latitude du marchand (coordonn√©es GPS)",
        example=40.7589,
        ge=-90,
        le=90
    )
    merch_long: float = Field(
        ...,
        description="Longitude du marchand (coordonn√©es GPS)",
        example=-73.9851,
        ge=-180,
        le=180
    )
    
    # Marchand
    merchant: str = Field(
        ...,
        description="Nom du marchand",
        example="Amazon"
    )
    category: str = Field(
        ...,
        description="Cat√©gorie de transaction",
        example="shopping_net"
    )
    
    # Client
    gender: str = Field(
        ...,
        description="Genre du client (M/F)",
        example="M"
    )
    state: str = Field(
        ...,
        description="√âtat (US)",
        example="NY"
    )
    dob: str = Field(
        ...,
        description="Date de naissance (YYYY-MM-DD)",
        example="1990-01-15"
    )
    
    # Transaction
    transaction_time: str = Field(
        ...,
        description="Heure de la transaction (YYYY-MM-DD HH:MM:SS)",
        example="2026-01-29 14:30:00"
    )
    
    class Config:
        schema_extra = {
            "example": {
                "cc_num": 374125201044065,
                "amt": 150.75,
                "lat": 40.7128,
                "long": -74.0060,
                "city_pop": 8000000,
                "zip": 10001,
                "merch_lat": 40.7589,
                "merch_long": -73.9851,
                "merchant": "Amazon",
                "category": "shopping_net",
                "gender": "M",
                "state": "NY",
                "dob": "1990-01-15",
                "transaction_time": "2026-01-29 14:30:00"
            }
        }


class FeaturesEngineeredOutput(BaseModel):
    """
    R√©sultat du Feature Engineering
    
    Contient les donn√©es originales + les features calcul√©es
    """
    # Donn√©es originales
    original_data: Dict[str, Any] = Field(
        ...,
        description="Donn√©es brutes d'entr√©e"
    )
    
    # Features engineered
    engineered_features: Dict[str, Any] = Field(
        ...,
        description="Nouvelles features calcul√©es"
    )
    
    # Toutes les features combin√©es
    all_features: Dict[str, Any] = Field(
        ...,
        description="Donn√©es originales + features engineered"
    )


class PreprocessedOutput(BaseModel):
    """
    R√©sultat du Preprocessing
    
    Features transform√©es (scaled + encoded) pr√™tes pour le mod√®le
    """
    preprocessed_shape: tuple = Field(
        ...,
        description="Dimensions des donn√©es preprocessed (lignes, colonnes)"
    )
    
    sample_values: List[float] = Field(
        ...,
        description="Premi√®res valeurs (pour debug)"
    )
    
    message: str = Field(
        ...,
        description="Message de confirmation"
    )


class PredictionOutput(BaseModel):
    """
    R√©sultat de la Pr√©diction de Fraude
    """
    # Pr√©diction
    is_fraud: bool = Field(
        ...,
        description="True si la transaction est frauduleuse"
    )
    
    fraud_probability: float = Field(
        ...,
        description="Probabilit√© de fraude (0.0 √† 1.0)",
        ge=0.0,
        le=1.0
    )
    
    # Classification du risque
    risk_level: str = Field(
        ...,
        description="Niveau de risque: LOW, MEDIUM, HIGH, CRITICAL"
    )
    
    # Confiance du mod√®le
    confidence: float = Field(
        ...,
        description="Confiance du mod√®le (0.0 √† 1.0)",
        ge=0.0,
        le=1.0
    )
    
    # M√©tadonn√©es
    timestamp: str = Field(
        ...,
        description="Heure de la pr√©diction (ISO format)"
    )
    
    processing_time_ms: float = Field(
        ...,
        description="Temps de traitement en millisecondes"
    )


# =====================================================================
# FONCTIONS HELPER
# =====================================================================

def load_models_from_hf():
    """
    T√©l√©charge et charge les mod√®les depuis HuggingFace Hub
    
    Cette fonction:
    1. T√©l√©charge fraud_model.pkl (le mod√®le ML)
    2. T√©l√©charge preprocessor.pkl (le preprocessor)
    3. Charge les 2 fichiers en m√©moire
    4. Met √† jour les variables globales model et preprocessor
    
    Returns:
        tuple: (success: bool, message: str)
            success = True si tout s'est bien pass√©
            message = Message d'information ou d'erreur
    """
    global model, preprocessor
    
    try:
        print("=" * 70)
        print("üì• T√©l√©chargement des mod√®les depuis HuggingFace...")
        print(f"   Repository: {REPO_ID}")
        print("=" * 70)
        
        # ========================================
        # 1. T√âL√âCHARGER LE MOD√àLE ML
        # ========================================
        
        print(f"\n‚¨áÔ∏è Download: {MODEL_FILENAME}...")
        model_path = hf_hub_download(
            repo_id=REPO_ID,
            filename=MODEL_FILENAME, # None = latest
            cache_dir="/tmp"         # Dossier de cache
        )
        print(f"‚úÖ T√©l√©charg√©: {model_path}")
        
        # Charger le mod√®le
        model = joblib.load(model_path)
        print(f"‚úÖ Mod√®le charg√©: {type(model).__name__}")
        
        # ========================================
        # 2. T√âL√âCHARGER LE PREPROCESSOR
        # ========================================
        
        print(f"\n‚¨áÔ∏è Download: {PREPROCESSOR_FILENAME}...")
        preprocessor_path = hf_hub_download(
            repo_id=REPO_ID,
            filename=PREPROCESSOR_FILENAME,
            cache_dir="/tmp"
        )
        print(f"‚úÖ T√©l√©charg√©: {preprocessor_path}")
        
        # Charger le preprocessor
        preprocessor = joblib.load(preprocessor_path)
        print(f"‚úÖ Preprocessor charg√©: {type(preprocessor).__name__}")
        
        print("\n" + "=" * 70)
        print("‚úÖ TOUS LES MOD√àLES SONT CHARG√âS ET PR√äTS")
        print("=" * 70)
        
        return True, "Models loaded successfully"
        
    except Exception as e:
        error_msg = f"Erreur lors du chargement des mod√®les: {str(e)}"
        print(f"\n‚ùå {error_msg}")
        return False, error_msg


def calculate_risk_level(probability: float) -> str:
    """
    Calcule le niveau de risque bas√© sur la probabilit√© de fraude
    
    Args:
        probability (float): Probabilit√© de fraude (0.0 √† 1.0)
    
    Returns:
        str: Niveau de risque (LOW, MEDIUM, HIGH, CRITICAL)
    
    Seuils:
        < 0.3  : LOW       (Risque faible)
        < 0.6  : MEDIUM    (Risque moyen)
        < 0.8  : HIGH      (Risque √©lev√©)
        >= 0.8 : CRITICAL  (Risque critique)
    """
    if probability < 0.3:
        return "LOW"
    elif probability < 0.6:
        return "MEDIUM"
    elif probability < 0.8:
        return "HIGH"
    else:
        return "CRITICAL"


# =====================================================================
# √âV√âNEMENT DE D√âMARRAGE
# =====================================================================

@app.on_event("startup")
async def startup_event():
    """
    Fonction appel√©e AU D√âMARRAGE de l'API
    
    Cette fonction:
    - Est ex√©cut√©e UNE SEULE FOIS quand l'API d√©marre
    - T√©l√©charge et charge les mod√®les en m√©moire
    - Les mod√®les restent en m√©moire pour toutes les requ√™tes
    
    Si les mod√®les ne se chargent pas, l'API d√©marre quand m√™me
    mais les endpoints de pr√©diction renverront une erreur 503.
    """
    print("\n" + "üöÄ" * 35)
    print("üöÄ D√âMARRAGE DE L'API FRAUD DETECTION")
    print("üöÄ" * 35)
    
    # Charger les mod√®les
    success, message = load_models_from_hf()
    
    if success:
        print("\n‚úÖ API pr√™te √† recevoir des requ√™tes!\n")
    else:
        print(f"\n‚ö†Ô∏è API d√©marr√©e mais mod√®les non charg√©s: {message}")
        print("‚ö†Ô∏è Les endpoints de pr√©diction ne fonctionneront pas.\n")


# =====================================================================
# ENDPOINTS - INFORMATION
# =====================================================================

@app.get(
    "/",
    tags=["üìä Information"],
    summary="Page d'accueil",
    description="Informations g√©n√©rales sur l'API"
)
async def root():
    """
    Endpoint racine - Informations sur l'API
    
    Retourne:
    - Nom de l'API
    - Version
    - Liens vers la documentation
    - Liste des endpoints disponibles
    """
    return {
        "message": "üö® Fraud Detection API - Level UP",
        "version": "2.0.0",
        "status": "online",
        "documentation": "/docs",
        "health_check": "/health",
        "endpoints": {
            "prediction": {
                "predict": "/predict - Pr√©diction compl√®te (feat_eng + preprocess + predict)",
            },
            "feature_engineering": {
                "feat_eng": "/feat_eng - Feature engineering seulement",
            },
            "preprocessing": {
                "preprocess": "/preprocess - Preprocessing seulement",
            },
            "information": {
                "model_info": "/model/info - Informations sur le mod√®le",
                "features": "/features - Liste des features n√©cessaires",
            }
        },
        "example_workflow": {
            "1": "Donn√©es brutes ‚Üí /feat_eng ‚Üí Features engineered",
            "2": "Features engineered ‚Üí /preprocess ‚Üí Features preprocessed",
            "3": "Features preprocessed ‚Üí /predict ‚Üí Pr√©diction",
            "shortcut": "Donn√©es brutes ‚Üí /predict ‚Üí Pr√©diction directe (recommand√©)"
        }
    }


@app.get(
    "/health",
    tags=["üìä Information"],
    summary="Health check",
    description="V√©rifier que l'API et les mod√®les sont op√©rationnels"
)
async def health_check():
    """
    V√©rifie l'√©tat de sant√© de l'API
    
    Retourne:
    - Status de l'API (healthy/unhealthy)
    - √âtat du mod√®le ML (loaded/not loaded)
    - √âtat du preprocessor (loaded/not loaded)
    - Timestamp
    """
    # V√©rifier si les mod√®les sont charg√©s
    models_loaded = (model is not None) and (preprocessor is not None)
    
    return {
        "status": "healthy" if models_loaded else "unhealthy",
        "model_loaded": model is not None,
        "preprocessor_loaded": preprocessor is not None,
        "model_repo": REPO_ID,
        "model_type": type(model).__name__ if model else None,
        "preprocessor_type": type(preprocessor).__name__ if preprocessor else None,
        "timestamp": datetime.utcnow().isoformat()
    }


@app.get(
    "/model/info",
    tags=["üìä Information"],
    summary="Informations sur le mod√®le",
    description="D√©tails techniques sur le mod√®le ML et le preprocessor"
)
async def model_info():
    """
    Informations d√©taill√©es sur le mod√®le ML
    
    Retourne:
    - Type de mod√®le
    - Repository HuggingFace
    - Nombre de features
    - Liste des features
    """
    # V√©rifier que les mod√®les sont charg√©s
    if model is None or preprocessor is None:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Models not loaded. Please check /health endpoint."
        )
    
    # R√©cup√©rer la liste des features
    features = get_model_features()
    
    return {
        "model": {
            "type": type(model).__name__,
            "repo_id": REPO_ID,
            "filename": MODEL_FILENAME,
            "version": MODEL_VERSION or "latest"
        },
        "preprocessor": {
            "type": type(preprocessor).__name__,
            "filename": PREPROCESSOR_FILENAME
        },
        "features": {
            "total": len(features),
            "numerical": 17,
            "categorical": 4,
            "list": features
        }
    }


@app.get(
    "/features",
    tags=["üìä Information"],
    summary="Liste des features",
    description="Liste compl√®te des features n√©cessaires pour une pr√©diction"
)
async def list_features():
    """
    Liste toutes les features attendues par le mod√®le
    
    Retourne:
    - Features num√©riques (17)
    - Features cat√©gorielles (4)
    - Total (21)
    """
    features = get_model_features()
    
    numerical = features[:17]  # Premi√®res 17 = num√©riques
    categorical = features[17:]  # Derni√®res 4 = cat√©gorielles
    
    return {
        "total_features": len(features),
        "numerical_features": {
            "count": len(numerical),
            "list": numerical
        },
        "categorical_features": {
            "count": len(categorical),
            "list": categorical
        },
        "all_features_in_order": features
    }


# =====================================================================
# ENDPOINTS - FEATURE ENGINEERING
# =====================================================================

@app.post(
    "/feat_eng",
    response_model=FeaturesEngineeredOutput,
    tags=["üîß Feature Engineering"],
    summary="Feature Engineering",
    description="Transforme les donn√©es brutes en features pour le mod√®le ML"
)
async def feature_engineering_endpoint(transaction: TransactionRawInput):
    """
    Applique le FEATURE ENGINEERING sur une transaction
    
    ## Ce que fait cet endpoint:
    
    1. **Calcul de distance GPS**
       - Calcule la distance entre le client et le marchand
       - Utilise la formule Haversine (pr√©cision: ¬±1%)
       - Feature cr√©√©e: `distance_km`
    
    2. **Extraction des features temporelles**
       - Heure de la journ√©e (0-23)
       - Jour de la semaine (0-6)
       - P√©riode (nuit, matin, apr√®s-midi, soir)
       - Weekend ou non
       - Heures de bureau ou non
       - Features cr√©√©es: `hour`, `dayofweek`, `is_night`, `is_morning`, 
         `is_afternoon`, `is_evening`, `is_business_hour`, `is_we`, 
         `year`, `month`, `day`
    
    3. **Calcul de l'√¢ge**
       - √Ä partir de la date de naissance
       - Feature cr√©√©e: `age`
    
    ## Input:
    Donn√©es brutes de la transaction (voir schema TransactionRawInput)
    
    ## Output:
    - `original_data`: Donn√©es brutes d'entr√©e
    - `engineered_features`: Nouvelles features calcul√©es
    - `all_features`: Toutes les features (original + engineered)
    
    ## Exemple d'utilisation:
    ```python
    import requests
    
    data = {
        "cc_num": 374125201044065,
        "amt": 150.75,
        "lat": 40.7128,
        "long": -74.0060,
        # ... autres champs
    }
    
    response = requests.post("http://localhost:8000/feat_eng", json=data)
    features = response.json()["all_features"]
    ```
    """
    try:
        # Convertir en dictionnaire
        transaction_dict = transaction.dict()
        
        print("\n" + "=" * 70)
        print("üîß FEATURE ENGINEERING")
        print("=" * 70)
        
        # Appliquer le feature engineering
        # (voir feature_engineering.py pour les d√©tails)
        engineered = engineer_features(transaction_dict)
        
        # Identifier les features qui ont √©t√© ajout√©es
        original_keys = set(transaction_dict.keys())
        all_keys = set(engineered.keys())
        new_features = all_keys - original_keys
        
        print(f"\n‚úÖ Feature engineering termin√©")
        print(f"   Features ajout√©es: {len(new_features)}")
        print(f"   Total features: {len(engineered)}")
        
        # Pr√©parer la r√©ponse
        return {
            "original_data": transaction_dict,
            "engineered_features": {k: engineered[k] for k in new_features},
            "all_features": engineered
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Feature engineering failed: {str(e)}"
        )


# =====================================================================
# ENDPOINTS - PREPROCESSING
# =====================================================================

@app.post(
    "/preprocess",
    response_model=PreprocessedOutput,
    tags=["‚öôÔ∏è Preprocessing"],
    summary="Preprocessing",
    description="Applique le preprocessing (scaling + encoding) sur les features"
)
async def preprocessing_endpoint(features: Dict[str, Any]):
    """
    Applique le PREPROCESSING sur les features
    
    ## Ce que fait cet endpoint:
    
    1. **StandardScaler** (normalisation)
       - Met les features num√©riques √† l'√©chelle
       - Moyenne = 0, √âcart-type = 1
       - Exemple: 100$ ‚Üí 0.52, 5000$ ‚Üí 2.31
    
    2. **OneHotEncoder** (encoding cat√©goriel)
       - Convertit les cat√©gories en colonnes binaires
       - Exemple: 'NY' ‚Üí [0, 0, 1, 0, ...] (vecteur de 50 dimensions)
       - Exemple: 'shopping_net' ‚Üí [0, 1, 0, ...] (vecteur de 14 dimensions)
    
    ## Input:
    Dictionnaire avec toutes les features (d√©j√† engineered)
    
    Les 21 features attendues:
    - **Num√©riques** (17): cc_num, amt, zip, city_pop, distance_km, age, 
      hour, is_night, is_morning, is_afternoon, is_evening, is_business_hour, 
      year, month, day, dayofweek, is_we
    - **Cat√©gorielles** (4): merchant, category, gender, state
    
    ## Output:
    - `preprocessed_shape`: Dimensions des donn√©es transform√©es
    - `sample_values`: Premi√®res valeurs (pour v√©rification)
    - `message`: Message de confirmation
    
    ## Note:
    Les donn√©es preprocessed ne sont PAS retourn√©es en entier 
    (trop volumineuses), seulement leur shape et un √©chantillon.
    
    Pour obtenir une pr√©diction, utilisez directement `/predict`
    qui fait feat_eng + preprocess + predict.
    """
    # V√©rifier que le preprocessor est charg√©
    if preprocessor is None:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Preprocessor not loaded"
        )
    
    try:
        print("\n" + "=" * 70)
        print("‚öôÔ∏è PREPROCESSING")
        print("=" * 70)
        
        # Pr√©parer les features pour le mod√®le
        # (s√©lectionne les bonnes colonnes dans le bon ordre)
        df = prepare_for_model(features)
        
        if df is None:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Missing required features. Use /features to see the full list."
            )
        
        print(f"\nüìä Features pr√©par√©es: {df.shape}")
        
        # Appliquer le preprocessing
        # Le preprocessor fait:
        # 1. StandardScaler sur les num√©riques
        # 2. OneHotEncoder sur les cat√©gorielles
        X_preprocessed = preprocessor.transform(df)
        
        print(f"‚úÖ Preprocessing termin√©: {X_preprocessed.shape}")
        print(f"   Input: {df.shape[1]} features")
        print(f"   Output: {X_preprocessed.shape[1]} features (apr√®s encoding)")
        
        # Retourner les informations (pas les donn√©es compl√®tes, trop volumineux)
        return {
            "preprocessed_shape": X_preprocessed.shape,
            "sample_values": X_preprocessed[0, :10].tolist(),  # 10 premi√®res valeurs
            "message": f"Preprocessing successful. Shape: {X_preprocessed.shape}"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Preprocessing failed: {str(e)}"
        )


# =====================================================================
# ENDPOINTS - PREDICTION
# =====================================================================

@app.post(
    "/predict",
    response_model=PredictionOutput,
    tags=["üéØ Prediction"],
    summary="Pr√©diction compl√®te",
    description="Pr√©diction de fraude compl√®te (feature engineering + preprocessing + ML)"
)
async def predict_fraud(transaction: TransactionRawInput):
    """
    Pr√©diction COMPL√àTE de fraude
    
    ## Workflow:
    
    ```
    Donn√©es Brutes (TransactionRawInput)
        ‚Üì
    1. Feature Engineering
        - Calcul distance GPS
        - Extraction features temporelles
        - Calcul √¢ge
        ‚Üì
    2. Preprocessing
        - StandardScaler (normalisation)
        - OneHotEncoder (encoding)
        ‚Üì
    3. Pr√©diction ML
        - RandomForestClassifier
        - Probabilit√© de fraude
        ‚Üì
    R√©sultat (PredictionOutput)
    ```
    
    ## Input:
    Donn√©es brutes de la transaction (voir TransactionRawInput schema)
    
    ## Output:
    - **is_fraud**: True/False - Transaction frauduleuse ou non
    - **fraud_probability**: 0.0 √† 1.0 - Probabilit√© de fraude
    - **risk_level**: LOW/MEDIUM/HIGH/CRITICAL - Niveau de risque
    - **confidence**: 0.0 √† 1.0 - Confiance du mod√®le
    - **timestamp**: Heure de la pr√©diction
    - **processing_time_ms**: Temps de traitement en millisecondes
    
    ## Niveaux de Risque:
    - **LOW**: fraud_probability < 0.3 ‚Üí Transaction probablement l√©gitime
    - **MEDIUM**: 0.3 ‚â§ fraud_probability < 0.6 ‚Üí V√©rification recommand√©e
    - **HIGH**: 0.6 ‚â§ fraud_probability < 0.8 ‚Üí Transaction suspecte
    - **CRITICAL**: fraud_probability ‚â• 0.8 ‚Üí Bloquer la transaction
    
    ## Exemple de Code:
    
    ```python
    import requests
    
    # Donn√©es de transaction
    transaction = {
        "cc_num": 374125201044065,
        "amt": 150.75,
        "lat": 40.7128,
        "long": -74.0060,
        "city_pop": 8000000,
        "zip": 10001,
        "merch_lat": 40.7589,
        "merch_long": -73.9851,
        "merchant": "Amazon",
        "category": "shopping_net",
        "gender": "M",
        "state": "NY",
        "dob": "1990-01-15",
        "transaction_time": "2026-01-29 14:30:00"
    }
    
    # Faire la pr√©diction
    response = requests.post(
        "http://localhost:8000/predict",
        json=transaction
    )
    
    result = response.json()
    
    if result["is_fraud"]:
        print(f"‚ö†Ô∏è FRAUDE d√©tect√©e! Probabilit√©: {result['fraud_probability']:.1%}")
        print(f"   Niveau de risque: {result['risk_level']}")
    else:
        print(f"‚úÖ Transaction l√©gitime. Probabilit√© de fraude: {result['fraud_probability']:.1%}")
    ```
    
    ## Performance:
    - Temps de traitement moyen: 10-50ms
    - Throughput: ~100-500 requ√™tes/seconde (selon hardware)
    
    ## Use Cases:
    1. **Validation temps r√©el**: Au moment du paiement
    2. **Post-transaction**: V√©rification apr√®s coup
    3. **Batch processing**: Analyse de milliers de transactions
    4. **Monitoring**: D√©tection de patterns de fraude
    """
    # V√©rifier que les mod√®les sont charg√©s
    if model is None or preprocessor is None:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Models not loaded. Please check /health endpoint."
        )
    
    try:
        # Timer pour mesurer le temps de traitement
        start_time = time.time()
        
        print("\n" + "üéØ" * 35)
        print("üéØ PR√âDICTION DE FRAUDE - WORKFLOW COMPLET")
        print("üéØ" * 35)
        
        # ========================================
        # √âTAPE 1: FEATURE ENGINEERING
        # ========================================
        
        print("\n[1/3] üîß Feature Engineering...")
        transaction_dict = transaction.dict()
        engineered = engineer_features(transaction_dict)
        
        # ========================================
        # √âTAPE 2: PREPROCESSING
        # ========================================
        
        print("\n[2/3] ‚öôÔ∏è Preprocessing...")
        df = prepare_for_model(engineered)
        
        if df is None:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Failed to prepare features for model"
            )
        
        # Appliquer le preprocessing
        X_preprocessed = preprocessor.transform(df)
        print(f"      Shape apr√®s preprocessing: {X_preprocessed.shape}")
        
        # ========================================
        # √âTAPE 3: PR√âDICTION ML
        # ========================================
        
        print("\n[3/3] ü§ñ Pr√©diction ML...")
        
        # Faire la pr√©diction
        prediction = model.predict(X_preprocessed)[0]  # 0 ou 1
        proba = model.predict_proba(X_preprocessed)[0]  # [proba_class_0, proba_class_1]
        
        # Extraire la probabilit√© de fraude (classe 1)
        fraud_prob = float(proba[1])
        
        # Calculer la confiance
        # Confiance = distance par rapport √† 0.5 (seuil de d√©cision)
        # Plus on est loin de 0.5, plus on est confiant
        confidence = abs(fraud_prob - 0.5) * 2
        
        # Calculer le niveau de risque
        risk = calculate_risk_level(fraud_prob)
        
        # Temps de traitement
        processing_time = (time.time() - start_time) * 1000  # En millisecondes
        
        # R√©sultat
        result = {
            "is_fraud": bool(prediction),
            "fraud_probability": round(fraud_prob, 4),
            "risk_level": risk,
            "confidence": round(confidence, 4),
            "timestamp": datetime.utcnow().isoformat(),
            "processing_time_ms": round(processing_time, 2)
        }
        
        print("\n" + "=" * 70)
        print(f"‚úÖ R√âSULTAT:")
        print(f"   Fraude: {result['is_fraud']}")
        print(f"   Probabilit√©: {result['fraud_probability']:.1%}")
        print(f"   Risque: {result['risk_level']}")
        print(f"   Temps: {result['processing_time_ms']:.2f}ms")
        print("=" * 70)
        
        return result
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Prediction failed: {str(e)}"
        )


# =====================================================================
# ERROR HANDLERS (Gestion des erreurs)
# =====================================================================

@app.exception_handler(ValueError)
async def value_error_handler(request, exc):
    """G√®re les erreurs de validation de donn√©es"""
    return JSONResponse(
        status_code=status.HTTP_400_BAD_REQUEST,
        content={
            "error": "Invalid input",
            "detail": str(exc),
            "type": "ValueError"
        }
    )


@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """G√®re toutes les autres erreurs inattendues"""
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "error": "Internal server error",
            "detail": "An unexpected error occurred",
            "type": type(exc).__name__
        }
    )


# =====================================================================
# POINT D'ENTR√âE
# =====================================================================

if __name__ == "__main__":
    """
    Lancer l'API en mode d√©veloppement
    
    Commande:
        python app.py
    
    Ou avec uvicorn:
        uvicorn app:app --reload --host 0.0.0.0 --port 8000
    
    Documentation:
        http://localhost:8000/docs
    """
    import uvicorn
    
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,  # Auto-reload en mode dev
        log_level="info"
    )
